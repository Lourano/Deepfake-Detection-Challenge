{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Notebook is a first part of Research to DFDC\n",
    "\n",
    "\n",
    "Advanced knowledge in probability theory, numerical methods will not give you much boost in your prediction ;)\n",
    "\n",
    "Since I have a weak computer with only 8 GB of RAM and don't have a GPU, also Kaggle limits me to 30 hours of weekly use, I donâ€™t have much opportunity to create a good predictor that can learn 500 GB of data :)).\n",
    "\n",
    "And so I decided to do the approximation of the outputs to real labels, and here is what came of it:\n",
    "\n",
    "I was able to squeeze 0.41423 from the ensemble of two architectures ResNext and XCeption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.figure_factory as ff\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestVideosDirectory = \"test_videos/\"\n",
    "\n",
    "TestVideos = sorted([x for x in os.listdir(TestVideosDirectory) if x[-4:] == \".mp4\"])\n",
    "\n",
    "Metadata = pd.read_csv('data/metadata')\n",
    "\n",
    "Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestVideoFilter = Metadata.filename.isin(TestVideos)\n",
    "\n",
    "TestData = Metadata[TestVideoFilter]\n",
    "\n",
    "TestData.sort_values(by = 'filename', inplace = True)\n",
    "\n",
    "TestData.reset_index(drop = True, inplace = True)\n",
    "\n",
    "TestData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission = pd.read_csv('data/submission-4.csv')\n",
    "\n",
    "Submission046 = pd.read_csv('data/sub0467x.csv')\n",
    "\n",
    "Submission['rlabel'] = TestData.label\n",
    "\n",
    "Submission.rlabel = Submission.rlabel.map({'FAKE': 1, 'REAL': 0})\n",
    "\n",
    "Submission.info()\n",
    "\n",
    "print(log_loss(Submission.rlabel, Submission.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(Submission.rlabel)\n",
    "\n",
    "sns.distplot(Submission.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(Submission.label)\n",
    "\n",
    "sns.distplot(Submission046.label)\n",
    "\n",
    "plt.legend(labels = ['better','046'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Just her coefs gave boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "\n",
    "SubmissionWithCalibration = Submission.copy()\n",
    "\n",
    "x = np.array(Submission.label)\n",
    "\n",
    "lr = LR(penalty = 'l2', dual = True, tol = 0.0001, C = 1.3, fit_intercept = True, intercept_scaling = 1.0, \n",
    "        \n",
    "        class_weight = None, random_state = None)     \n",
    "\n",
    "lr.fit(x.reshape(-1, 1), Submission.rlabel)   \n",
    "\n",
    "p_calibrated = lr.predict_proba(x.reshape(-1, 1))[:,1]\n",
    "\n",
    "print(lr.coef_)\n",
    "\n",
    "print(lr.intercept_)\n",
    "\n",
    "print(log_loss(SubmissionWithCalibration.rlabel, p_calibrated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(Submission.rlabel)\n",
    "\n",
    "sns.distplot(p_calibrated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isotonic Regression\n",
    "\n",
    "Waste of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.isotonic import IsotonicRegression as IR\n",
    "\n",
    "ir = IR() # out_of_bounds = 'clip'\n",
    "\n",
    "ir.fit(Submission.label, Submission.rlabel)\n",
    "\n",
    "IRp_calibrated = ir.transform(Submission.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(Submission.rlabel)\n",
    "\n",
    "sns.distplot(IRp_calibrated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(n_estimators = 300)\n",
    "\n",
    "xgb.fit(x.reshape(-1, 1), Submission.rlabel)\n",
    "\n",
    "XGBCalibrated = xgb.predict_proba(x.reshape(-1, 1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(Submission.rlabel)\n",
    "\n",
    "sns.distplot(XGBCalibrated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SubmissionWithCalibration['IRCalibration'] = IRp_calibrated\n",
    "\n",
    "SubmissionWithCalibration['LRCalibration'] = p_calibrated\n",
    "\n",
    "SubmissionWithCalibration['XGBCalibration'] =  XGBCalibrated\n",
    "\n",
    "SubmissionWithCalibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best submission on kaggle \", log_loss(SubmissionWithCalibration.rlabel, SubmissionWithCalibration.label))\n",
    "\n",
    "print(\"Isotonic Regression calibration\", log_loss(SubmissionWithCalibration.rlabel, SubmissionWithCalibration.IRCalibration))\n",
    "\n",
    "print(\"Logistic Regression calibration\", log_loss(SubmissionWithCalibration.rlabel, SubmissionWithCalibration.LRCalibration))\n",
    "\n",
    "print(\"XGBoost calibration\", log_loss(SubmissionWithCalibration.rlabel, SubmissionWithCalibration.XGBCalibration))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
